# zookeeper学习笔记

## Zookeeper：分布式协调服务

1. 配置管理（1M的数据）
2. 分布式同步（临时节点）
   - 分布式锁（设置一个临时节点，不能是序列节点）；
   - 锁依托一个父节点，且具备 -s ，说明这个父节点可以有多把锁，后面的锁盯着前面的锁（带队列或者事务模式的锁）
   - 集群管理，HA高可用选择主节点
   - 分布式ID生成器
3. 分组管理（path结构，父子节点）
4. 命名（序列节点）

## 官方网站

```http
https://zookeeper.apache.org/
```

## 下载地址

```http
https://zookeeper.apache.org/releases.html
```

## 文档地址

```http
https://zookeeper.apache.org/doc/r3.6.2/zookeeperOver.html
```

## 集群特征

zookeeper实现非常注重高性能、高可用性、严格有序的访问。可以在大型分布式系统中使用，可靠性使其不会成为单点故障，严格有序意味着可以在客户端实现复杂的同步原语。

zookeeper可以当作集群使用，很少会使用单实例。集群的两种方式：1.主从复制集群，2.无主集群（redis cluster无主模型，且数据是分片的）；对于数据来说：1.数据同步集群（每个节点存储全量数据），2.数据分片集群。

zookeeper是主从复制集群，每个节点的数据是完全一样的。写（增删改）只能发生在leader上，查可以发生在所有的节点上。主是单点，依然会存在单点的问题；

![zookeeper集群](images\zookeeper集群.png)

## 性能测试

ZooKeeper吞吐量，随读/写比的变化而定。在读取数量超过写入次数的应用程序中，由于写入涉及同步所有服务器的状态，因此该性能特别高。（对于协调服务来说，读取次数多于写入次数）。ZooKeeper应用程序可在数千台计算机上运行，并且在读取比写入更常见的情况下，其性能最佳，比率约为10：1。

![ZooKeeper吞吐量-随读-写比的变化而定](images\ZooKeeper吞吐量-随读-写比的变化而定.jpg)

横轴：读取所占的比例，纵轴：每秒的查询量。当全是读取的时候，就算是3个节点的集群也能喉住80000+的请求数量。

存在错误时的可靠性表明部署如何响应各种故障。图中标记的事件如下：

1. 追随者的失败和恢复
2. 失败和其他追随者的恢复
3. 领导者的失败
4. 两个追随者的失败和恢复
5. 另一个领导者的失败

![zookeeper存在错误时的可靠性](images\zookeeper存在错误时的可靠性.jpg)

1. 追随者失败并迅速恢复，则ZooKeeper能够在失败的情况下维持高吞吐量。
2. 领导者选举算法允许 leader 恢复得足够快，ZooKeeper只需不到200毫秒即可选出新的领导者。
3. 随着追随者的恢复，ZooKeeper能够在开始处理请求后再次提高吞吐量。

## 数据结构

Zookeeper 的数据结构类似于文件系统，不同的是 zookeeper 的每个节点都可以存储少量的数据，最大支持存储1M的数据。zookeeper数据保存在内存中，可以实现高吞吐量和低延迟数量。

![zookeeper数据结构](images\zookeeper数据结构.jpg)

- 目录树结构
  - 持久节点（PERSISTENT）：节点创建后，一直存在，直到主动删除了该节点。
  - 临时节点（EPHEMERAL）：生命周期和客户端会话绑定，一旦客户端会话失效，这个节点就会自动删除。
  - 序列节点（SEQUENTIAL）：多个线程创建同一个顺序节点时候，每个线程会得到一个带有编号的节点，节点编号是递增不重复的

## 优势

ZooKeeper非常快速且非常简单。但是，由于其目标是作为构建更复杂的服务（例如同步）的基础，因此它提供了一组保证。这些是：

- 顺序一致性：来自客户端的更新将按照发送的顺序应用（写请求由主节点进行）
- 原子性：更新成功或失败，没有部分结果（过半成功，并同步节点和数据）
- 单个系统映像：无论客户端连接到哪个服务器，客户端都将看到相同的服务视图（主从复制模型决定的）
- 可靠性：应用更新后，此更新将一直持续到客户端覆盖更新为止（持久性）
- 及时性：确保系统的客户视图在特定时间范围内是最新的（最终一致性，过半）

## 配置文件属性描述

1. tickTime：默认2000，单位ms，主从之间心跳的时间间隔

2. initLimit：默认10次，从节点和主节点建立连接的时候，主节点允许 initLimit * tickTime 的时间延迟

3. syncLimit：默认5次，主节点下发同步任务时，从节点如果在 syncLimit * tickTime 的时间内没有返回的时候，就认为有问题

4. dataDir：数据持久化存储路径

5. clientPort：默认2181，客户端连接服务端的端口

6. maxClientCnxnx：最大客户端连接数，默认60

7. 集群配置：过半数：行数/2+1

   - server.1=node01:2888:3888
   - server.2=node02:2888:3888
   - server.3=node03:2888:3888
   - server.4=node04:2888:3888

   2888端口的作用：当是leader的时候，开启的和从节点建立通信的端口，用于数据同步。

   3888端口的作用：当无主的时候，通过这个端口建立连接，进行投票，选择一个leader，让这个leader开启一个2888的端口，其他节点连接这个leader的2888的端口进行通信

8. 启动zookeeper之前，准备myid，并配置环境变量；具体安装过程参考【大数据中的安全过程】

   echo 1 > dataDir/myid

   echo 2 > dataDir/myid

   echo 3 > dataDir/myid

   echo 4 > dataDir/myid

## 主节点选举流程

> 第一次启动：按照启动顺序，当达到过半数时，server.n中n最大的那台机器就是leader。后面再启动其他节点时，即使有server.n比当前leader的n大，也只能追随当前leader节点。
>
> 运行一段时间时候，再启动时leader的选择逻辑时，先看哪些节点的数据最完整（看事务id的最大值进行比较），如果都比较完整，再看server.n中n的最大值，是leader。

![zookeeper建立连接的过程](images\zookeeper建立连接的过程.png)

## 数据时二进制安全的

外面的客户端给我推送什么样的字节数据，我原封不动的给你存进来，你那边的编解码器我不关心

## 全局事务id

> zookeeper是顺序执行的，体现在这个id身上的，所有的这种增删改这种写操作，他们都会递交给leader，因为leader是单机，所以单机维护一个单调递增的计数器很容器。

1. 事务id：一个64位的字节；0x代表16进制，16进制的每一位代表4个2进制位，那么两位代表一个字节(8位)，低32位是事务递增序列，高32位表示的是第几代leader。每次leader更新换代，后面的事务id从0开始重新计算。
2. cZxid：创建节点的事务id
3. mZxid：修改节点的事务id
4. pZxid：当前节点创建的最后那一个的节点的事务id
5. ephemeralOwner：没有归属谁，则说明不是临时节点；有值说明是临时节点，归属一个sessionID
6. 客户端连接服务端之后，客户端挂了sessionID就没了，那么临时节点就会被删除掉
7. 客户端连接服务端之后，服务端挂了，那么临时节点是否会丢失？
   - 不会丢失
   - 因为zookeeper统一了视图（单个系统影像），连sessionID都会被同步到所有的集群节点里
   - 一个新的客户端连接进来，会消耗一个事务id，说明client的sessionID会写给所有节点
   - 客户端断开连接时，会走一个删除的逻辑，要进行统一视图，所有节点都会删，会再次消耗一个事务id

## 原语api支持

- *create* : 在树中的某个位置创建一个节点
  - -e 表示创建的是一个临时节点
  - -s 多个线程创建同一个顺序节点时，每个线程会得到一个带有编号的节点，节点编号是递增不重复的（不会覆盖创建，分布式情况下统一命名）
- *delete* : 删除节点
- *exists* : 测试某个节点是否存在于某个位置
- *get data* : 从节点读取数据
- *set data* : 将数据写入节点
- *get children* : 检索节点的子节点列表
- *sync* : 等待数据传播

